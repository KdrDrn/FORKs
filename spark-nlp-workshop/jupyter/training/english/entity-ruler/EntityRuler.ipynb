{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1953uewL-Jll"
   },
   "outputs": [],
   "source": [
    "# Install pyspark\n",
    "! pip install --ignore-installed pyspark\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLNO3Z9r6HgR"
   },
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JfeD8Rj-as2",
    "outputId": "44b908fe-7ae0-4d1a-af09-0d1539fb5fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Spark version: 3.0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark NLP version\", sparknlp.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the default configuration (useStorage=true). This parameter tells the annotator to serialize patterns file data with RocksDB storage when saving the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_eB72Yzg8_Jx"
   },
   "outputs": [],
   "source": [
    "data = spark.createDataFrame([[\"Lord Eddard Stark was the head of House Stark. John Snow lives in Winterfell.\"]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdrsm2rfrACF"
   },
   "source": [
    "We are going to use a JSON file with the following format:\n",
    "\n",
    "\n",
    "```\n",
    "[\n",
    "  {\n",
    "    \"label\": \"PERSON\",\n",
    "    \"patterns\": [\"Jon\", \"John\", \"John Snow\"]\n",
    "  },\n",
    "  {\n",
    "    \"label\": \"PERSON\",\n",
    "    \"patterns\": [\"Eddard\", \"Eddard Stark\"]\n",
    "  },\n",
    "  {\n",
    "    \"label\": \"LOCATION\",\n",
    "    \"patterns\": [\"Winterfell\"]\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRyju8D-6XJ1"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "sentence_detector = SentenceDetector().setInputCols(\"document\").setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "  .setInputCols(\"document\") \\\n",
    "  .setOutputCol(\"token\") \\\n",
    "  .setExceptions([\"John Snow\", \"Eddard Stark\"])\n",
    "\n",
    "entity_ruler = EntityRulerApproach() \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"entity\") \\\n",
    "    .setPatternsResource(\"sample_data/patterns.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhKPEMb09w6a"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, entity_ruler])\n",
    "model = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7mjcA2E_ehu",
    "outputId": "7183d640-6540-4266-e3c0-51dfcdeba36c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|entity                                                                                                                                                                                                        |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[chunk, 5, 16, Eddard Stark, [entity -> PERSON, sentence -> 0], []], [chunk, 47, 55, John Snow, [entity -> PERSON, sentence -> 1], []], [chunk, 66, 75, Winterfell, [entity -> LOCATION, sentence -> 1], []]]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(data).select(\"entity\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LAxooiQNYVv"
   },
   "source": [
    "We can define an id field to identify entities and it supports JSON Lines format as the example below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hm5gn2G8OFHu"
   },
   "source": [
    "```\n",
    "{\"id\": \"names-with-j\", \"label\": \"PERSON\", \"patterns\": [\"Jon\", \"John\", \"John Snow\"]}\n",
    "{\"id\": \"names-with-e\", \"label\": \"PERSON\", \"patterns\": [\"Eddard\", \"Eddard Stark\"]}\n",
    "{\"id\": \"locations\", \"label\": \"LOCATION\", \"patterns\": [\"Winterfell\"]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_4a1QYaNPfr"
   },
   "outputs": [],
   "source": [
    "entity_ruler = EntityRulerApproach() \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"entity\") \\\n",
    "    .setPatternsResource(\"sample_data/patterns.jsonl\", ReadAs.TEXT, options={\"format\": \"JSONL\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cd0sNKNeOcUg",
    "outputId": "836db0a5-8607-4690-8578-251e35f9bee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|entity                                                                                                                                                                                                                                                                 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[chunk, 5, 16, Eddard Stark, [entity -> PERSON, id -> names-with-e, sentence -> 0], []], [chunk, 47, 55, John Snow, [entity -> PERSON, id -> names-with-j, sentence -> 1], []], [chunk, 66, 75, Winterfell, [entity -> LOCATION, id -> locations, sentence -> 1], []]]|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, entity_ruler])\n",
    "model = pipeline.fit(data)\n",
    "model.transform(data).select(\"entity\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDZ21hp3rOHV"
   },
   "source": [
    "For the CSV file we use the following format:\n",
    "\n",
    "\n",
    "```\n",
    "PERSON|Jon\n",
    "PERSON|John\n",
    "PERSON|John Snow\n",
    "LOCATION|Winterfell\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HLcNfrdoAmP"
   },
   "outputs": [],
   "source": [
    "entity_ruler_csv = EntityRulerApproach() \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"entity\") \\\n",
    "    .setPatternsResource(\"sample_data/patterns.csv\", options={\"format\": \"csv\", \"delimiter\": \"\\\\|\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYTuwztwoHIK"
   },
   "outputs": [],
   "source": [
    "pipeline_csv = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, entity_ruler_csv])\n",
    "model_csv = pipeline_csv.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qEN-zRNQoLu5",
    "outputId": "a0401dae-8dee-4de3-8bf6-35505511feee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|entity                                                                                                                                   |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[chunk, 47, 55, John Snow, [entity -> PERSON, sentence -> 1], []], [chunk, 66, 75, Winterfell, [entity -> LOCATION, sentence -> 1], []]]|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_csv.transform(data).select(\"entity\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmLiqAYhn5DT"
   },
   "source": [
    "# Regex Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4h5Ulxyn-rE"
   },
   "source": [
    "This annotator can also find matches based on regex patterns defined on pattern field. For example we can have the JSON file below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJ1vi-J8pO8W"
   },
   "source": [
    "```\n",
    "[\n",
    "  {\n",
    "    \"id\": \"person-regex\",\n",
    "    \"label\": \"PERSON\",\n",
    "    \"patterns\": [\"\\\\w+\\\\s\\\\w+\", \"\\\\w+-\\\\w+\"]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"locations-words\",\n",
    "    \"label\": \"LOCATION\",\n",
    "    \"patterns\": [\"Winterfell\"]\n",
    "  }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJvrwk18pGqk"
   },
   "outputs": [],
   "source": [
    "regex_entity_ruler = EntityRulerApproach() \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"entity\") \\\n",
    "    .setPatternsResource(\"sample_data/regex_patterns.json\") \\\n",
    "    .setEnablePatternRegex(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v8TbKbo0Izg"
   },
   "outputs": [],
   "source": [
    "regex_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, regex_entity_ruler])\n",
    "regex_model = regex_pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pl63WAaq0TKa",
    "outputId": "9ac9ef7a-d9b7-409c-bedb-c76fc7c4a43c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|entity                                                                                                                                                                                                                                                                       |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[chunk, 5, 16, Eddard Stark, [entity -> PERSON, id -> person-regex, sentence -> 0], []], [chunk, 47, 55, John Snow, [entity -> PERSON, id -> person-regex, sentence -> 1], []], [chunk, 66, 75, Winterfell, [entity -> LOCATION, id -> locations-words, sentence -> 1], []]]|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regex_model.transform(data).select(\"entity\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "EntityRuler.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
